{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mixQTL inputs for GTEx v8 data\n",
    "\n",
    "This notebook describes the pre-processing steps required for running the mixQTL model in tensorQTL using data fr om the GTEx v8 release:\n",
    "1. Converting the phased VCF to haplotype dosages, stored as two separate Parquet files.\n",
    "2. Converting the per-individual ASE files to per-tissue summaries.\n",
    "\n",
    "The input files can be retrieved from [AnVIL](https://anvil.terra.bio/#workspaces/anvil-datastorage/AnVIL_GTEx_V8_hg38) (required dbGaP access). The ASE files are in [GTEx_Analysis_2017-06-05_v8_ASE_WASP_counts_by_subject](gs://fc-secure-ff8156a3-ddf3-42e4-9211-0fd89da62108/GTEx_Analysis_2017-06-05_v8_ASE_WASP_counts_by_subject/) and the VCF in [GTEx_Analysis_2017-06-05_v8_WGS_VCF_files](gs://fc-secure-ff8156a3-ddf3-42e4-9211-0fd89da62108/GTEx_Analysis_2017-06-05_v8_WGS_VCF_files/).\n",
    "\n",
    "The GTF file `gencode.v26.GRCh38.genes.gtf` required for remapping variants to genes in the ASE files is available [here](https://console.cloud.google.com/storage/browser/_details/gtex-resources/GENCODE/gencode.v26.GRCh38.genes.gtf) and from the [GTEx Portal](https://gtexportal.org/home/datasets).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import os\n",
    "import subprocess\n",
    "import glob\n",
    "from collections import defaultdict\n",
    "from bx.intervals.intersection import IntervalTree\n",
    "import qtl.annotation as annotation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert VCF to haplotype dosages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = 'python3 ../utils/vcf2hap.py \\\n",
    "    GTEx_Analysis_2017-06-05_v8_WholeGenomeSeq_838Indiv_Analysis_Freeze.SHAPEIT2_phased.MAF01.vcf.gz \\\n",
    "    --output_dir .'\n",
    "subprocess.check_call(cmd, shell=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the dosages can then be loaded as\n",
    "hap1_df = pd.read_parquet('GTEx_Analysis_2017-06-05_v8_WholeGenomeSeq_838Indiv_Analysis_Freeze.SHAPEIT2_phased.MAF01.hap1.parquet')\n",
    "hap2_df = pd.read_parquet('GTEx_Analysis_2017-06-05_v8_WholeGenomeSeq_838Indiv_Analysis_Freeze.SHAPEIT2_phased.MAF01.hap2.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate ASE reads by tissue and gene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) convert ASE tables to parquet for faster processing\n",
    "ase_files = {os.path.basename(i).split('.')[0]:i for i in glob.glob('GTEx_Analysis_v8_ASE_WASP_counts_by_subject/*.v8.wasp_corrected.ase_table.tsv.gz')}\n",
    "for k, donor_id in enumerate(sorted(ase_files), 1):\n",
    "    print('\\rProcessing participant {}/{}'.format(k, len(ase_files)), end='')\n",
    "    df = pd.read_csv(ase_files[donor_id], sep='\\t')\n",
    "    df.to_parquet('GTEx_Analysis_v8_ASE_WASP_counts_by_subject_parquet/{}.v8.wasp_corrected.ase_table.parquet'.format(donor_id))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aggregate_ase(ase_file_dict, tissue_abbrv, gene_interval_trees, filter_flagged=True):\n",
    "    \"\"\"Aggregate ASE counts per gene, and generate table for the selected tissue\"\"\"\n",
    "    cumul_df = []\n",
    "    for k, donor_id in enumerate(sorted(ase_files), 1):\n",
    "        print('\\rProcessing participant {}/{}'.format(k, len(ase_files)), end='')\n",
    "\n",
    "        if ase_files[donor_id].endswith('.parquet'):\n",
    "            df = pd.read_parquet(ase_files[donor_id])\n",
    "        else:\n",
    "            df = pd.read_csv(ase_files[donor_id], sep='\\t')\n",
    "\n",
    "        df = df[df['TISSUE_ID']==tissue_abbrv]\n",
    "\n",
    "        if filter_flagged:\n",
    "            df = df[(df['LOW_MAPABILITY']==0) & \n",
    "                    (df['MAPPING_BIAS_SIM']==0) & \n",
    "                    (df['GENOTYPE_WARNING']==0)]\n",
    "\n",
    "        # gene IDs in ASE files are from VEP, remap using \n",
    "        # collapsed gene model instead, so that they match eQTLs\n",
    "        df.rename(columns={'GENE_ID':'GENE_ID_VEP'}, inplace=True)\n",
    "        \n",
    "        gene_ids = []\n",
    "        for chrom, pos in zip(df['CHR'], df['POS']):\n",
    "            cand = gene_interval_trees[chrom].find(pos, pos)\n",
    "            if len(cand) == 0:\n",
    "                gene_ids.append(np.NaN)\n",
    "            elif len(cand) == 1:\n",
    "                gene_ids.append(cand[0].id)\n",
    "            else:  # should never happen with collapsed model\n",
    "                raise ValueError('Multiple matches')\n",
    "        df['GENE_ID'] = gene_ids\n",
    "        df = df[df['GENE_ID'].notnull()]\n",
    "        df = df.sort_values(['TISSUE_ID', 'GENE_ID'])\n",
    "\n",
    "        if df.shape[0] > 0:\n",
    "            ref_cumul = defaultdict(int)\n",
    "            alt_cumul = defaultdict(int)\n",
    "            for gene_id, ref, alt in zip(df['GENE_ID'], df['REF_COUNT'], df['ALT_COUNT']):\n",
    "                ref_cumul[gene_id] += ref\n",
    "                alt_cumul[gene_id] += alt\n",
    "            cdf = pd.concat([pd.Series(ref_cumul, name='ref'), pd.Series(alt_cumul, name='alt')], axis=1)\n",
    "            cdf.index.name = 'gene_id'\n",
    "            cdf['donor_id'] = donor_id\n",
    "            cumul_df.append(cdf)\n",
    "    cumul_df = pd.concat(cumul_df, axis=0).reset_index()\n",
    "    cumul_df = cumul_df.sort_values(['gene_id', 'donor_id']).reset_index(drop=True)\n",
    "    return cumul_df\n",
    "\n",
    "\n",
    "annot = annotation.Annotation('gencode.v26.GRCh38.genes.gtf', verbose=False)\n",
    "gene_interval_trees = defaultdict()\n",
    "for g in annot.genes:\n",
    "    for e in g.transcripts[0].exons:\n",
    "        gene_interval_trees.setdefault(g.chr, IntervalTree()).add(e.start_pos, e.end_pos+1, g)\n",
    "\n",
    "ase_files = {os.path.basename(i).split('.')[0]:i for i in glob.glob('GTEx_Analysis_v8_ASE_WASP_counts_by_subject_parquet/*.v8.wasp_corrected.ase_table.parquet')}\n",
    "ase_df = aggregate_ase(ase_files, 'WHLBLD', gene_interval_trees, filter_flagged=True)\n",
    "ase_df.to_parquet('Whole_Blood.v8.wasp_corrected.ase_gene.parquet')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
